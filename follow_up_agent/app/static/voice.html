<!--<!DOCTYPE html>-->
<!--<html lang="en">-->
<!--<head>-->
<!--    <meta charset="UTF-8">-->
<!--    <meta name="viewport" content="width=device-width, initial-scale=1.0">-->
<!--    <title>Voice Follow-Up Assistant</title>-->
<!--    <style>-->
<!--        * { margin: 0; padding: 0; box-sizing: border-box; }-->
<!--        body { font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); height: 100vh; display: flex; justify-content: center; align-items: center; }-->
<!--        .container { width: 450px; height: 650px; background: white; border-radius: 15px; box-shadow: 0 10px 40px rgba(0,0,0,0.2); display: flex; flex-direction: column; }-->
<!--        .header { background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; padding: 20px; border-radius: 15px 15px 0 0; text-align: center; position: relative; }-->
<!--        .mode-switch { position: absolute; top: 15px; right: 15px; }-->
<!--        .mode-btn { background: rgba(255,255,255,0.2); border: 2px solid white; color: white; padding: 8px 15px; border-radius: 20px; cursor: pointer; font-size: 12px; font-weight: 600; transition: all 0.3s; }-->
<!--        .mode-btn:hover { background: white; color: #667eea; }-->
<!--        .voice-area { flex: 1; display: flex; flex-direction: column; align-items: center; justify-content: center; padding: 40px; background: #f8f9fa; }-->
<!--        .status-text { font-size: 16px; color: #666; margin-bottom: 30px; text-align: center; min-height: 50px; }-->
<!--        .mic-button { width: 120px; height: 120px; border-radius: 50%; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); border: none; cursor: pointer; display: flex; align-items: center; justify-content: center; font-size: 48px; color: white; transition: all 0.3s; box-shadow: 0 5px 20px rgba(102, 126, 234, 0.4); }-->
<!--        .mic-button:hover { transform: scale(1.1); box-shadow: 0 8px 30px rgba(102, 126, 234, 0.6); }-->
<!--        .mic-button:disabled { opacity: 0.5; cursor: not-allowed; transform: scale(1); }-->
<!--        .mic-button.active { background: #ef4444; animation: pulse 1.5s infinite; }-->
<!--        @keyframes pulse { 0%, 100% { box-shadow: 0 5px 20px rgba(239, 68, 68, 0.4); } 50% { box-shadow: 0 5px 40px rgba(239, 68, 68, 0.8); } }-->
<!--        .transcript-area { width: 100%; max-height: 200px; overflow-y: auto; margin-top: 30px; padding: 15px; background: white; border-radius: 10px; font-size: 14px; color: #333; }-->
<!--        .transcript-item { margin: 10px 0; padding: 8px; border-radius: 5px; }-->
<!--        .user-transcript { background: #e3e8ff; text-align: right; }-->
<!--        .assistant-transcript { background: #f0f0f0; }-->
<!--        .audio-indicator { margin-top: 20px; color: #667eea; font-weight: 600; font-size: 14px; }-->
<!--    </style>-->
<!--</head>-->
<!--<body>-->
<!--    <div class="container">-->
<!--        <div class="header">-->
<!--            <div class="mode-switch">-->
<!--                <button class="mode-btn" onclick="window.location.href='/'">ðŸ’¬ Chat Mode</button>-->
<!--            </div>-->
<!--            <h2>ðŸŽ¤ Voice Follow-Up Assistant</h2>-->
<!--            <p style="font-size: 14px; opacity: 0.9;">Post-Consultation Care - Voice Mode</p>-->
<!--        </div>-->
<!--        <div class="voice-area">-->
<!--            <div class="status-text" id="statusText">Click the microphone to start</div>-->
<!--            <button class="mic-button" id="micButton" onclick="toggleMic()">ðŸŽ¤</button>-->
<!--            <div class="audio-indicator" id="audioIndicator"></div>-->
<!--            <div class="transcript-area" id="transcriptArea"></div>-->
<!--        </div>-->
<!--    </div>-->

<!--    <script>-->
<!--        let ws = null;-->
<!--        let mediaRecorder = null;-->
<!--        let audioContext = null;-->
<!--        let isRecording = false;-->
<!--        let isSpeaking = false;-->
<!--        let audioElement = null;-->

<!--        function updateStatus(text) {-->
<!--            document.getElementById('statusText').textContent = text;-->
<!--        }-->

<!--        function addTranscript(text, isUser) {-->
<!--            const area = document.getElementById('transcriptArea');-->
<!--            const div = document.createElement('div');-->
<!--            div.className = `transcript-item ${isUser ? 'user-transcript' : 'assistant-transcript'}`;-->
<!--            div.textContent = text;-->
<!--            area.appendChild(div);-->
<!--            area.scrollTop = area.scrollHeight;-->
<!--        }-->

<!--        async function toggleMic() {-->
<!--            if (!isRecording) {-->
<!--                await startRecording();-->
<!--            } else {-->
<!--                stopRecording();-->
<!--            }-->
<!--        }-->

<!--        async function startRecording() {-->
<!--            try {-->
<!--                // Request microphone access-->
<!--                const stream = await navigator.mediaDevices.getUserMedia({-->
<!--                    audio: {-->
<!--                        channelCount: 1,-->
<!--                        sampleRate: 16000,-->
<!--                        echoCancellation: true,-->
<!--                        noiseSuppression: true-->
<!--                    }-->
<!--                });-->

<!--                // Connect to WebSocket-->
<!--                ws = new WebSocket(`ws://${window.location.host}/api/followup/ws/voice`);-->

<!--                ws.onopen = () => {-->
<!--                    console.log('WebSocket connected');-->
<!--                    updateStatus('Connected! Listening...');-->
<!--                };-->

<!--                ws.onmessage = async (event) => {-->
<!--                    if (event.data instanceof Blob) {-->
<!--                        // Audio response-->
<!--                        console.log('Received audio blob');-->
<!--                        await playAudio(event.data);-->
<!--                    } else {-->
<!--                        const data = JSON.parse(event.data);-->
<!--                        console.log('Received:', data);-->

<!--                        if (data.type === 'status') {-->
<!--                            updateStatus(data.message);-->
<!--                        } else if (data.type === 'interim_transcript') {-->
<!--                            updateStatus(`You: ${data.text}...`);-->
<!--                        } else if (data.type === 'transcript') {-->
<!--                            addTranscript(data.text, true);-->
<!--                        } else if (data.type === 'response') {-->
<!--                            addTranscript(data.text, false);-->
<!--                            updateStatus('Speaking...');-->
<!--                        } else if (data.type === 'audio_complete') {-->
<!--                            console.log('Audio playback complete');-->
<!--                            document.getElementById('audioIndicator').textContent = '';-->
<!--                            // Re-enable mic after AI finishes speaking-->
<!--                            if (isSpeaking) {-->
<!--                                setTimeout(() => {-->
<!--                                    isSpeaking = false;-->
<!--                                    enableMic();-->
<!--                                }, 500);-->
<!--                            }-->
<!--                        } else if (data.type === 'error') {-->
<!--                            updateStatus(`Error: ${data.message}`);-->
<!--                        }-->
<!--                    }-->
<!--                };-->

<!--                ws.onerror = (error) => {-->
<!--                    console.error('WebSocket error:', error);-->
<!--                    updateStatus('Connection error');-->
<!--                };-->

<!--                ws.onclose = () => {-->
<!--                    console.log('WebSocket closed');-->
<!--                    updateStatus('Disconnected');-->
<!--                    stopRecording();-->
<!--                };-->

<!--                // Setup audio recording-->
<!--                audioContext = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 16000 });-->
<!--                const source = audioContext.createMediaStreamSource(stream);-->

<!--                mediaRecorder = new MediaRecorder(stream, {-->
<!--                    mimeType: 'audio/webm'-->
<!--                });-->

<!--                mediaRecorder.ondataavailable = (event) => {-->
<!--                    if (event.data.size > 0 && ws && ws.readyState === WebSocket.OPEN) {-->
<!--                        ws.send(event.data);-->
<!--                    }-->
<!--                };-->

<!--                mediaRecorder.start(250); // Send chunks every 250ms-->
<!--                isRecording = true;-->

<!--                document.getElementById('micButton').classList.add('active');-->
<!--                document.getElementById('micButton').textContent = 'â¸ï¸';-->

<!--            } catch (error) {-->
<!--                console.error('Error starting recording:', error);-->
<!--                updateStatus('Microphone access denied');-->
<!--            }-->
<!--        }-->

<!--        function stopRecording() {-->
<!--            if (mediaRecorder && mediaRecorder.state !== 'inactive') {-->
<!--                mediaRecorder.stop();-->
<!--            }-->
<!--            if (ws) {-->
<!--                ws.close();-->
<!--            }-->
<!--            if (audioContext) {-->
<!--                audioContext.close();-->
<!--            }-->
<!--            isRecording = false;-->
<!--            document.getElementById('micButton').classList.remove('active');-->
<!--            document.getElementById('micButton').textContent = 'ðŸŽ¤';-->
<!--            updateStatus('Stopped');-->
<!--        }-->

<!--        async function playAudio(audioBlob) {-->
<!--            return new Promise((resolve) => {-->
<!--                isSpeaking = true;-->
<!--                disableMic();-->

<!--                const url = URL.createObjectURL(audioBlob);-->
<!--                audioElement = new Audio(url);-->

<!--                document.getElementById('audioIndicator').textContent = 'ðŸ”Š AI Speaking...';-->

<!--                audioElement.onended = () => {-->
<!--                    URL.revokeObjectURL(url);-->
<!--                    resolve();-->
<!--                };-->

<!--                audioElement.onerror = () => {-->
<!--                    console.error('Audio playback error');-->
<!--                    URL.revokeObjectURL(url);-->
<!--                    isSpeaking = false;-->
<!--                    enableMic();-->
<!--                    resolve();-->
<!--                };-->

<!--                audioElement.play().catch(err => {-->
<!--                    console.error('Play error:', err);-->
<!--                    isSpeaking = false;-->
<!--                    enableMic();-->
<!--                    resolve();-->
<!--                });-->
<!--            });-->
<!--        }-->

<!--        function disableMic() {-->
<!--            const micButton = document.getElementById('micButton');-->
<!--            micButton.disabled = true;-->
<!--            micButton.style.opacity = '0.5';-->
<!--        }-->

<!--        function enableMic() {-->
<!--            const micButton = document.getElementById('micButton');-->
<!--            micButton.disabled = false;-->
<!--            micButton.style.opacity = '1';-->
<!--            updateStatus('Listening...');-->
<!--        }-->

<!--        // Cleanup on page unload-->
<!--        window.addEventListener('beforeunload', () => {-->
<!--            stopRecording();-->
<!--        });-->
<!--    </script>-->
<!--</body>-->
<!--</html>-->


<!--new voice ui generated by chatgpt-->

<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0"/>
<title>Medilligence â€¢ Follow-Up Voice</title>

<style>
* { margin: 0; padding: 0; box-sizing: border-box; }

body {
    font-family: "Segoe UI", system-ui, sans-serif;
    background: #f4f7fb;
    height: 100vh;
    display: flex;
    justify-content: center;
    align-items: center;
}

/* Container */
.voice-container {
    width: 100%;
    max-width: 820px;
    height: 92vh;
    background: #ffffff;
    border-radius: 18px;
    box-shadow: 0 18px 40px rgba(0,0,0,0.12);
    display: flex;
    flex-direction: column;
    overflow: hidden;
}

/* Header */
.voice-header {
    background: #2563eb;
    color: white;
    padding: 16px 20px;
    display: flex;
    align-items: center;
    gap: 12px;
}

.voice-header .back {
    cursor: pointer;
    font-size: 18px;
}

.voice-header h1 {
    font-size: 18px;
    font-weight: 600;
}

.voice-header p {
    font-size: 12px;
    opacity: 0.9;
}

/* Chat Area */
.voice-messages {
    flex: 1;
    padding: 20px;
    background: #f9fafb;
    overflow-y: auto;
}

.message {
    display: flex;
    margin-bottom: 14px;
}

.message.user { justify-content: flex-end; }
.message.assistant { justify-content: flex-start; }

.bubble {
    max-width: 70%;
    padding: 12px 16px;
    border-radius: 16px;
    font-size: 14px;
    line-height: 1.5;
}

.message.user .bubble {
    background: #2563eb;
    color: white;
    border-bottom-right-radius: 4px;
}

.message.assistant .bubble {
    background: #eef2f7;
    color: #1f2937;
    border-bottom-left-radius: 4px;
}

/* Voice Bar */
.voice-bar {
    border-top: 1px solid #e5e7eb;
    padding: 14px 18px;
    display: flex;
    align-items: center;
    gap: 14px;
    background: #ffffff;
}

.chat-icon {
    width: 42px;
    height: 42px;
    border-radius: 50%;
    border: none;
    background: #e0e7ff;
    color: #2563eb;
    font-size: 18px;
    cursor: pointer;

    display: flex;
    align-items: center;      /* vertical center */
    justify-content: center;
}

.mic-area {
    flex: 1;
    background: #f3f4f6;
    border-radius: 28px;
    padding: 10px 16px;
    display: flex;
    align-items: center;
    justify-content: center;
    gap: 10px;
    cursor: pointer;
}

.mic {
    width: 44px;
    height: 44px;
    border-radius: 50%;
    background: #2563eb;
    color: white;
    font-size: 20px;
    display: flex;
    align-items: center;
    justify-content: center;
}

.mic.listening {
    animation: pulse 1.4s infinite;
}

@keyframes pulse {
    0% { box-shadow: 0 0 0 0 rgba(37,99,235,0.6); }
    70% { box-shadow: 0 0 0 14px rgba(37,99,235,0); }
    100% { box-shadow: 0 0 0 0 rgba(37,99,235,0); }
}

.status {
    font-size: 13px;
    color: #374151;
}

.clear-btn {
    font-size: 12px;
    background: none;
    border: none;
    color: #6b7280;
    cursor: pointer;
}
</style>
</head>

<body>

<div class="voice-container">

    <!-- Header -->
    <div class="voice-header">
        <div class="back" onclick="goToChat()">ðŸ’¬</div>
        <div>
            <h1>Medilligence</h1>
            <p>Follow-Up Voice â€¢ Post-Consultation Care</p>
        </div>
    </div>

    <!-- Chat -->
    <div class="voice-messages" id="chat">
        <div class="message assistant">
<!--            <div class="bubble">-->
<!--&lt;!&ndash;                Hello! Iâ€™m your follow-up care assistant. How are you feeling today?&ndash;&gt;-->
<!--            </div>-->
        </div>
    </div>

    <!-- Voice Bar -->
    <div class="voice-bar">
        <button class="chat-icon" onclick="goToChat()">ðŸ’¬</button>

        <div class="mic-area" id="micButton">
            <div class="mic" id="micIcon">ðŸŽ¤</div>
            <div class="status" id="status">Tap to speak</div>
        </div>

        <button class="clear-btn" id="clearBtn">Clear</button>
    </div>

</div>

<script>
let ws = null;
let mediaRecorder = null;
let audioContext = null;
let isListening = false;

const chat = document.getElementById("chat");
const statusEl = document.getElementById("status");
const micIcon = document.getElementById("micIcon");
const micButton = document.getElementById("micButton");
const clearBtn = document.getElementById("clearBtn");

function goToChat() {
    window.location.href = "/";
}

function addMessage(text, isUser) {
    const msg = document.createElement("div");
    msg.className = "message " + (isUser ? "user" : "assistant");

    const bubble = document.createElement("div");
    bubble.className = "bubble";
    bubble.textContent = text;

    msg.appendChild(bubble);
    chat.appendChild(msg);
    chat.scrollTop = chat.scrollHeight;
}

function updateStatus(text, listening=false) {
    statusEl.textContent = text;
    micIcon.classList.toggle("listening", listening);
}

micButton.addEventListener("click", async () => {
    if (!ws) {
        connectWebSocket();
        return;
    }

    if (isListening) stopListening();
    else startListening();
});

function connectWebSocket() {
    const protocol = location.protocol === "https:" ? "wss:" : "ws:";
    ws = new WebSocket(`${protocol}//${location.host}/api/followup/ws/voice`);

    ws.onopen = () => {
        updateStatus("Listeningâ€¦", true);
        startListening();
    };

    ws.onmessage = async (event) => {
        if (event.data instanceof Blob) {
            playAudio(event.data);
        } else {
            const data = JSON.parse(event.data);
            if (data.type === "transcript") addMessage(data.text, true);
            if (data.type === "response") addMessage(data.text, false);
        }
    };

    ws.onclose = () => {
        ws = null;
        updateStatus("Tap to speak");
        isListening = false;
    };
}

async function startListening() {
    isListening = true;
    updateStatus("Listeningâ€¦", true);
}

function stopListening() {
    isListening = false;
    updateStatus("Tap to speak");
}

function playAudio(blob) {
    const url = URL.createObjectURL(blob);
    const audio = new Audio(url);
    audio.onended = () => URL.revokeObjectURL(url);
    audio.play();
}

clearBtn.onclick = () => {
    chat.innerHTML = "";
    updateStatus("Tap to speak");
};
</script>

</body>
</html>
