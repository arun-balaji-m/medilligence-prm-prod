<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0"/>
<title>Medilligence â€¢ Follow-Up Voice</title>

<style>
* { margin: 0; padding: 0; box-sizing: border-box; }

body {
    font-family: "Segoe UI", system-ui, sans-serif;
    background: #f4f7fb;
    height: 100vh;
    display: flex;
    justify-content: center;
    align-items: center;
}

/* Container */
.voice-container {
    width: 100%;
    max-width: 820px;
    height: 92vh;
    background: #ffffff;
    border-radius: 18px;
    box-shadow: 0 18px 40px rgba(0,0,0,0.12);
    display: flex;
    flex-direction: column;
    overflow: hidden;
}

/* Header */
.voice-header {
    background: #2563eb;
    color: white;
    padding: 16px 20px;
    display: flex;
    align-items: center;
    gap: 12px;
}

.voice-header .back {
    cursor: pointer;
    font-size: 18px;
}

.voice-header h1 {
    font-size: 18px;
    font-weight: 600;
}

.voice-header p {
    font-size: 12px;
    opacity: 0.9;
}

/* Chat Area */
.voice-messages {
    flex: 1;
    padding: 20px;
    background: #f9fafb;
    overflow-y: auto;
}

.message {
    display: flex;
    margin-bottom: 14px;
}

.message.user { justify-content: flex-end; }
.message.assistant { justify-content: flex-start; }

.bubble {
    max-width: 70%;
    padding: 12px 16px;
    border-radius: 16px;
    font-size: 14px;
    line-height: 1.5;
}

.message.user .bubble {
    background: #2563eb;
    color: white;
    border-bottom-right-radius: 4px;
}

.message.assistant .bubble {
    background: #eef2f7;
    color: #1f2937;
    border-bottom-left-radius: 4px;
}

/* Voice Bar */
.voice-bar {
    border-top: 1px solid #e5e7eb;
    padding: 14px 18px;
    display: flex;
    align-items: center;
    gap: 14px;
    background: #ffffff;
}

.chat-icon {
    width: 42px;
    height: 42px;
    border-radius: 50%;
    border: none;
    background: #e0e7ff;
    color: #2563eb;
    font-size: 18px;
    cursor: pointer;

    display: flex;
    align-items: center;      /* vertical center */
    justify-content: center;
}

.mic-area {
    flex: 1;
    background: #f3f4f6;
    border-radius: 28px;
    padding: 10px 16px;
    display: flex;
    align-items: center;
    justify-content: center;
    gap: 10px;
    cursor: pointer;
}

.mic {
    width: 44px;
    height: 44px;
    border-radius: 50%;
    background: #2563eb;
    color: white;
    font-size: 20px;
    display: flex;
    align-items: center;
    justify-content: center;
}

.mic.listening {
    animation: pulse 1.4s infinite;
}

@keyframes pulse {
    0% { box-shadow: 0 0 0 0 rgba(37,99,235,0.6); }
    70% { box-shadow: 0 0 0 14px rgba(37,99,235,0); }
    100% { box-shadow: 0 0 0 0 rgba(37,99,235,0); }
}

.status {
    font-size: 13px;
    color: #374151;
}

.clear-btn {
    font-size: 12px;
    background: none;
    border: none;
    color: #6b7280;
    cursor: pointer;
}
</style>
</head>

<body>

<div class="voice-container">


    <div class="voice-header">
        <div class="back" onclick="goToChat()">ðŸ’¬</div>
        <div>
            <h1>Medilligence</h1>
            <p>Follow-Up Voice â€¢ Post-Consultation Care</p>
        </div>
    </div>


    <div class="voice-messages" id="chat">
        <div class="message assistant">
        </div>
    </div>


    <div class="voice-bar">
        <button class="chat-icon" onclick="goToChat()">ðŸ’¬</button>

        <div class="mic-area" id="micButton">
            <div class="mic" id="micIcon">ðŸŽ¤</div>
            <div class="status" id="status">Tap to speak</div>
        </div>

        <button class="clear-btn" id="clearBtn">Clear</button>
    </div>

</div>

<script>
let ws = null;
let audioContext = null;
let isListening = false;
let audioQueue = [];
let isPlayingAudio = false;

const chat = document.getElementById("chat");
const statusEl = document.getElementById("status");
const micIcon = document.getElementById("micIcon");
const micButton = document.getElementById("micButton");
const clearBtn = document.getElementById("clearBtn");

function goToChat() {
    window.location.href = "./";
}

function addMessage(text, isUser) {
    const msg = document.createElement("div");
    msg.className = "message " + (isUser ? "user" : "assistant");

    const bubble = document.createElement("div");
    bubble.className = "bubble";
    bubble.textContent = text;

    msg.appendChild(bubble);
    chat.appendChild(msg);
    chat.scrollTop = chat.scrollHeight;
}

function updateStatus(text, listening = false) {
    statusEl.textContent = text;
    micIcon.classList.toggle("listening", listening);

    if (text === "Listening...") {
        micButton.classList.remove("disabled");
    } else {
        micButton.classList.add("disabled");
    }
}


async function initAudio() {
    audioContext = new (window.AudioContext || window.webkitAudioContext)({
        sampleRate: 16000
    });

    await audioContext.resume();

    const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
    const source = audioContext.createMediaStreamSource(stream);

    await audioContext.audioWorklet.addModule("static/pcm-processor.js");

    const worklet = new AudioWorkletNode(audioContext, "pcm-processor");

    worklet.port.onmessage = (event) => {
        if (ws?.readyState === WebSocket.OPEN) {
            ws.send(event.data); // raw PCM
        }
    };

    source.connect(worklet);
    worklet.connect(audioContext.destination);
}


micButton.addEventListener("click", async () => {
    if (micButton.classList.contains("disabled")) return;

    if (!ws) {
        updateStatus("Connecting...");
        await connectWebSocket();
        return;
    }

    isListening ? stopListening() : startListening();
});

function startListening() {
    isListening = true;
    updateStatus("Listeningâ€¦", true);
}

function stopListening() {
    isListening = false;
    updateStatus("Processing...");
}


async function connectWebSocket() {
    await initAudio();

    const protocol = location.protocol === "https:" ? "wss:" : "ws:";
<!--    ws = new WebSocket(`${protocol}//${location.host}/api/followup/ws/voice`);-->

    const pathParts = location.pathname.split('/').filter(p => p);
    const basePath = pathParts.length > 0 ? `/${pathParts[0]}` : '';

    ws = new WebSocket(`${protocol}//${location.host}${basePath}/api/followup/ws/voice`);

    ws.onopen = () => {
        updateStatus("Connected");
    };

    ws.onmessage = async (event) => {
        if (event.data instanceof Blob) {
            audioQueue.push(event.data);
            if (!isPlayingAudio) playNextAudio();
            return;
        }

        const data = JSON.parse(event.data);

        if (data.type === "status") {
            updateStatus(data.message, data.message === "Listening...");
        }
        else if (data.type === "interim_transcript") {
            updateStatus("Hearing: " + data.text.slice(0, 30) + "â€¦", true);
        }
        else if (data.type === "transcript") {
            addMessage(data.text, true);
        }
        else if (data.type === "response") {
            addMessage(data.text, false);
        }
    };

    ws.onclose = () => {
        ws = null;
        updateStatus("Tap to speak");
    };
}


async function playNextAudio() {
    if (!audioQueue.length) {
        isPlayingAudio = false;
        return;
    }

    isPlayingAudio = true;
    const blob = audioQueue.shift();

    const buffer = await audioContext.decodeAudioData(await blob.arrayBuffer());
    const source = audioContext.createBufferSource();
    source.buffer = buffer;
    source.connect(audioContext.destination);
    source.onended = playNextAudio;
    source.start();
}

clearBtn.onclick = () => {
    chat.innerHTML = "";
    updateStatus("Tap to speak");
};

window.addEventListener("beforeunload", () => {
    ws?.close();
});
</script>

</body>
</html>
